---
spark:
  app.name: user_activity_sink
  hive.exec.dynamic.partition: 'true'
  hive.exec.dynamic.partition.mode: nonstrict

input:
  type: kafka
  kafka.bootstrap.servers: localhost:9092
  startingOffsets: earliest
  subscribe: user-activity

transformer:
  type: value_only_as_json
  infer.schema: false
  topic.schema:
    userId : string
    pageId : string
    activityType : string
    transactionTime : timestamp

sink:
  type: hive
  checkpoint.location: checkpoint/kafka_sink_checkpoint
  trigger.interval: '60'
  table.name: user_activity_2
  write.mode: append
